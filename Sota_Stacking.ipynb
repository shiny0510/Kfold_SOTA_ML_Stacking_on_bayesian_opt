{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58f69195",
   "metadata": {},
   "source": [
    "Seung-Hwan Oh, Seoul, Korea\n",
    "\n",
    "Modified by Seung-Hwan Oh 2022.12.27\n",
    "\n",
    "Do not copy without permission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b84c8f41-8c9f-4e9c-9969-e98541e822af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f899fd-fbb4-48bc-9ec5-3eb5a68564cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b37f7e-a9f2-4640-8a0c-80ecdc626740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df):\n",
    "    if 'class' in df.columns:\n",
    "        df_x = df.drop(columns=['id', 'class'])\n",
    "        df_y = df['class']\n",
    "        return df_x, df_y\n",
    "    else:\n",
    "        df_x = df.drop(columns=['id'])\n",
    "        return df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05bd5dc3-5caf-4691-a836-d05d79353a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = get_x_y(train)\n",
    "test_x = get_x_y(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f79fbb3-bdd5-4bf7-bcc2-3776f1de653b",
   "metadata": {},
   "source": [
    "## Label-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689a42a5-140f-4282-9f33-6b319dea89a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_le = preprocessing.LabelEncoder()\n",
    "snp_le = preprocessing.LabelEncoder()\n",
    "snp_col = [f'SNP_{str(x).zfill(2)}' for x in range(1,16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2329a4f8-92b2-484d-acbd-2bb8079929e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_data = []\n",
    "for col in snp_col:\n",
    "    snp_data += list(train_x[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be7c4c4e-9c40-4c2e-bbce-5109dc16e802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = class_le.fit_transform(train_y)\n",
    "snp_le.fit(snp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a6855cf-8261-45dd-b18b-660aaf0ab141",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_x.columns:\n",
    "    if col in snp_col:\n",
    "        train_x[col] = snp_le.transform(train_x[col])\n",
    "        test_x[col] = snp_le.transform(test_x[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c06e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=train_x.iloc[:int(len(train_x)*0.8),:]\n",
    "#x_val=train_x.iloc[int(len(train_x)*0.8):,:]\n",
    "#y_train=train_y[:int(len(train_y)*0.8)]\n",
    "#y_val=train_y[int(len(train_y)*0.8):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0b8a2e4",
   "metadata": {},
   "source": [
    "# 1. LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ca32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb  \n",
    "from sklearn.metrics import f1_score\n",
    "def lgb_cv(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda, x_data=None, y_data=None, n_splits=5, output='score'):\n",
    "    score = 0\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(x_data):\n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(\n",
    "            num_leaves = int(num_leaves), \n",
    "            learning_rate = learning_rate, \n",
    "            n_estimators = int(n_estimators), \n",
    "            subsample = np.clip(subsample, 0, 1), \n",
    "            colsample_bytree = np.clip(colsample_bytree, 0, 1), \n",
    "            reg_alpha = reg_alpha, \n",
    "            reg_lambda = reg_lambda\n",
    "        )\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        pred = model.predict(x_valid)\n",
    "        \n",
    "        score += f1_score(pred,y_valid, average='macro')/n_splits\n",
    "    \n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9082fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial  \n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 모델과 관련없는 변수 고정\n",
    "func_fixed = partial(lgb_cv, x_data=train_x, y_data=train_y, n_splits=5, output='score') \n",
    "# 베이지안 최적화 범위 설정\n",
    "lgbBO = BayesianOptimization(\n",
    "    func_fixed, \n",
    "    {\n",
    "        'num_leaves': (16, 1024),        # num_leaves,       범위(16~1024)\n",
    "        'learning_rate': (0.0001, 0.1),  # learning_rate,    범위(0.0001~0.1)\n",
    "        'n_estimators': (16, 1024),      # n_estimators,     범위(16~1024)\n",
    "        'subsample': (0, 1),             # subsample,        범위(0~1)\n",
    "        'colsample_bytree': (0, 1),      # colsample_bytree, 범위(0~1)\n",
    "        'reg_alpha': (0, 10),            # reg_alpha,        범위(0~10)\n",
    "        'reg_lambda': (0, 50),           # reg_lambda,       범위(0~50)\n",
    "    }, \n",
    "    random_state=4321                    # 시드 고정\n",
    ")\n",
    "lgbBO.maximize(init_points=10, n_iter=30) # 처음 5회 랜덤 값으로 score 계산 후 30회 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d764fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  colsam... | learni... | n_esti... | num_le... | reg_alpha | reg_la... | subsample\n",
    "#  0.2182    | 0.03022   | 877.3     | 28.61     | 0.06825   | 1.223     | 0.9198 \n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    num_leaves = int(28.61), \n",
    "    learning_rate = 0.03022, \n",
    "    n_estimators = int(877), \n",
    "    subsample = np.clip(0.9198, 0, 1), \n",
    "    colsample_bytree = np.clip(0.2182, 0, 1),  \n",
    "    reg_alpha = 0.06825, \n",
    "    reg_lambda = 1.223\n",
    ")\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "preds = model.predict(test_x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e82c079c",
   "metadata": {},
   "source": [
    "# 2. XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb \n",
    "from sklearn.metrics import f1_score\n",
    "def xgb_cv(max_depth,learning_rate,n_estimators,reg_alpha, x_data=None, y_data=None, n_splits=5, output='score'):\n",
    "    score = 0\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(x_data):\n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "        \n",
    "        model = xgb.XGBClassifier(max_depth=int(max_depth),\n",
    "                                           learning_rate= learning_rate,\n",
    "                                           n_estimators= int(n_estimators),\n",
    "                                           reg_alpha = reg_alpha,\n",
    "                                           nthread = -1,\n",
    "                                           objective='binary:logistic',\n",
    "                                         )\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        pred = model.predict(x_valid)\n",
    "        \n",
    "        score += f1_score(pred,y_valid, average='macro')/n_splits\n",
    "    \n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial  \n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "func_fixed = partial(xgb_cv, x_data=train_x, y_data=train_y, n_splits=5, output='score') \n",
    "\n",
    "lgbBO = BayesianOptimization(\n",
    "    func_fixed, \n",
    "    {\n",
    "    'max_depth': (5,100),\n",
    "    'learning_rate': (0, 0.001),\n",
    "    'n_estimators' : (1,500),\n",
    "    'reg_alpha': (0,1)\n",
    "    }, \n",
    "    random_state=4321                    # 시드 고정\n",
    ")\n",
    "lgbBO.maximize(init_points=10, n_iter=30) # 처음 10회 랜덤 score 계산 후 30회 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "592d7d4e",
   "metadata": {},
   "source": [
    "# 3.catBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18b0d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from catboost import Pool, cv, CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "def cat_cv(n_estimators, depth, learning_rate, max_bin,\n",
    "              num_leaves, l2_leaf_reg, model_size_reg,  output='score'):\n",
    "    score = 0\n",
    "    kf = KFold(n_splits=5)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(train_x):\n",
    "        x_train, y_train = train_x.iloc[train_index], train_y[train_index]\n",
    "        x_valid, y_valid = train_x.iloc[valid_index], train_y[valid_index]\n",
    "        \n",
    "        model = CatBoostClassifier(\n",
    "                            n_estimators = int(n_estimators),\n",
    "                            learning_rate = learning_rate,\n",
    "                            l2_leaf_reg = l2_leaf_reg,\n",
    "                            max_depth = int(depth),\n",
    "                            num_leaves = int(num_leaves),\n",
    "                            random_state = 88,\n",
    "                            grow_policy = \"Lossguide\",\n",
    "                            #task_type=\"GPU\",\n",
    "                            max_bin = int(max_bin),  \n",
    "                            model_size_reg = model_size_reg,\n",
    "                            \n",
    "                            )\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        pred = model.predict(x_valid)\n",
    "        \n",
    "        score += f1_score(pred,y_valid, average='macro')/5\n",
    "    \n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5448127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial  \n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "pbounds = {\"n_estimators\": (10,1000),\n",
    "           \"depth\": (2,15),\n",
    "           \"learning_rate\": (.001, 1),\n",
    "           \"num_leaves\": (1,40),\n",
    "           \"max_bin\":(1,300),\n",
    "           \"l2_leaf_reg\":(0,10),\n",
    "           \"model_size_reg\": (0,10)\n",
    "}\n",
    "optimizer = BayesianOptimization(\n",
    "    f = cat_cv,\n",
    "    pbounds = pbounds,\n",
    "    verbose = 2,\n",
    "    random_state = 888\n",
    ")\n",
    "optimizer.maximize(init_points=3, n_iter=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82f1214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.9651203791990541,\n",
       " 'params': {'depth': 14.125960987190359,\n",
       "  'l2_leaf_reg': 3.34251629303533,\n",
       "  'learning_rate': 0.10945208281572452,\n",
       "  'max_bin': 291.9920003682243,\n",
       "  'model_size_reg': 4.257909146774925,\n",
       "  'n_estimators': 46.577536813828516,\n",
       "  'num_leaves': 34.88455908498228}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed49048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "                    n_estimators = int(46.577536813828516),\n",
    "                    learning_rate = 0.10945208281572452,\n",
    "                    l2_leaf_reg = 3.34251629303533,\n",
    "                    max_depth = int(14.125960987190359),\n",
    "                    num_leaves = int(34.88455908498228),\n",
    "                    random_state = 88,\n",
    "                    grow_policy = \"Lossguide\",\n",
    "                    max_bin = int(291.9920003682243),  \n",
    "                    model_size_reg = 4.257909146774925,\n",
    "                    \n",
    "                    )\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "preds = model.predict(test_x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b758d06",
   "metadata": {},
   "source": [
    "# 4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9906ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import lightgbm as lgb  \n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def cat_cv(xg_max_depth,xg_learning_rate,xg_n_estimators,xg_reg_alpha, xg_gamma ,xg_min_child_weight, xg_subsample  ,xg_colsample_bytree,\n",
    "           lgb_num_leaves, lgb_learning_rate, lgb_n_estimators, lgb_subsample, lgb_colsample_bytree, lgb_reg_alpha, lgb_reg_lambda,\n",
    "           cat_n_estimators, cat_depth, cat_learning_rate, cat_max_bin, cat_num_leaves, cat_l2_leaf_reg, cat_model_size_reg, \n",
    "                                                                                output='score'):\n",
    "    score = 0\n",
    "    kf = KFold(n_splits=5)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(train_x):\n",
    "        x_train, y_train = train_x.iloc[train_index], train_y[train_index]\n",
    "        x_valid, y_valid = train_x.iloc[valid_index], train_y[valid_index]\n",
    "        \n",
    "        \n",
    "        base_models = [('rf_1', xgb.XGBClassifier(max_depth=int(xg_max_depth),\n",
    "                                           learning_rate= xg_learning_rate,\n",
    "                                           n_estimators= int(xg_n_estimators),\n",
    "                                           reg_alpha = xg_reg_alpha,\n",
    "                                           nthread = -1,\n",
    "                                           min_child_weight=xg_min_child_weight,\n",
    "                                            gamma=xg_gamma,\n",
    "                                            subsample=xg_subsample,\n",
    "                                            colsample_bytree=xg_colsample_bytree, \n",
    "                                           \n",
    "                                           )),\n",
    "                                           \n",
    "                        ('rf_2', lgb.LGBMClassifier(\n",
    "                                num_leaves = int(lgb_num_leaves), \n",
    "                                learning_rate = lgb_learning_rate, \n",
    "                                n_estimators = int(lgb_n_estimators), \n",
    "                                subsample = np.clip(lgb_subsample, 0, 1), \n",
    "                                colsample_bytree = np.clip(lgb_colsample_bytree, 0, 1), \n",
    "                                reg_alpha = lgb_reg_alpha, \n",
    "                                reg_lambda = lgb_reg_lambda\n",
    "                         )) ]\n",
    "\n",
    "        # stacking 설정\n",
    "        model = StackingClassifier(estimators=base_models, final_estimator=CatBoostClassifier(n_estimators = int(cat_n_estimators),\n",
    "                                                        learning_rate = cat_learning_rate,\n",
    "                                                        l2_leaf_reg = cat_l2_leaf_reg,\n",
    "                                                        max_depth = int(cat_depth),\n",
    "                                                        num_leaves = int(cat_num_leaves),\n",
    "                                                        random_state = 88,\n",
    "                                                        grow_policy = \"Lossguide\",\n",
    "                                                        max_bin = int(cat_max_bin),  \n",
    "                                                        logging_level='Silent',\n",
    "                                                        model_size_reg = cat_model_size_reg\n",
    "                                                        ))\n",
    "                                    \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        pred = model.predict(x_valid)\n",
    "        \n",
    "        score += f1_score(pred,y_valid, average='macro')/5\n",
    "    \n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models\n",
    "\n",
    "\n",
    "\n",
    "# 베이지안 최적화 범위 설정\n",
    "pbounds = {\"cat_n_estimators\": (10,1000),\n",
    "           \"cat_depth\": (2,15),\n",
    "           \"cat_learning_rate\": (0.001, 1),\n",
    "           \"cat_num_leaves\": (1,40),\n",
    "           \"cat_max_bin\":(1,300),\n",
    "           \"cat_l2_leaf_reg\":(0,10),\n",
    "           \"cat_model_size_reg\": (0,10),\n",
    "\n",
    "           'lgb_num_leaves': (16, 1024),        \n",
    "            'lgb_learning_rate': (0.001, 1), \n",
    "            'lgb_n_estimators': (16, 1024),     \n",
    "            'lgb_subsample': (0, 1),             \n",
    "            'lgb_colsample_bytree': (0, 1),     \n",
    "            'lgb_reg_alpha': (0, 10),            \n",
    "            'lgb_reg_lambda': (0, 50),           \n",
    "\n",
    "            'xg_max_depth': (1,100),\n",
    "            'xg_learning_rate': (0.001, 1),\n",
    "            'xg_n_estimators' : (1,1000),\n",
    "            'xg_reg_alpha': (0,1),\n",
    "            'xg_gamma': (0, 100),\n",
    "            'xg_min_child_weight': (0, 3),\n",
    "            'xg_subsample': (0.5, 1),\n",
    "            'xg_colsample_bytree' :(0.2, 1)\n",
    "            \n",
    "}\n",
    "optimizer = BayesianOptimization(\n",
    "    f = cat_cv,\n",
    "    pbounds = pbounds,\n",
    "    verbose = 2,\n",
    "    random_state = 888\n",
    ")\n",
    "optimizer.maximize(init_points=2, n_iter=30) # 처음 5회 랜덤 값으로 score 계산 후 30회 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7611963-8c2f-484a-8d9f-01b89db7d162",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16b405-8a2d-4567-aebf-79ad596a1cd9",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fd0adb4-81ad-4474-8d31-51dff217f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2875bcba-91d1-4ecc-a839-370a16f14b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ohseunghwan/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "submit['class'] = class_le.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58d59d36-c023-4ded-8734-bd7cef2efc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e4cbb29f4f6800676aeea16249aea6e0abca8b0d722b80bdd9fa32583e0c32a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
